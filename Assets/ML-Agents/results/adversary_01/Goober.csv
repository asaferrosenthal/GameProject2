Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,99.0,-1.0914278,0.025252525252525252,0.025252525252525252,1.0
20000,1.4189383,99.0,-1.1544602,0.0875,0.0875,1.0
30000,None,99.0,-1.170419,0.0375,0.0375,1.0
40000,1.4194189,99.0,-1.5437567,0.0375,0.0375,1.0
50000,1.4209868,99.0,-0.9127901,0.1625,0.1625,1.0
60000,None,99.0,-0.842161,0.075,0.075,1.0
70000,1.4209868,99.0,-0.99403983,0.09,0.09,1.0
80000,1.4213771,99.0,-0.96355283,0.09,0.09,1.0
90000,1.4213772,99.0,-0.8570316,0.0775,0.0775,1.0
100000,1.419939,99.0,-0.8791535,0.0775,0.0775,1.0
110000,None,99.0,-0.89961976,0.0875,0.0875,1.0
120000,1.4191927,99.0,-0.9998583,0.065,0.065,1.0
130000,1.4190865,99.0,-0.9663587,0.075,0.075,1.0
140000,None,99.0,-1.3109726,0.05,0.05,1.0
150000,1.4156742,99.0,-0.9337604,0.1175,0.1175,1.0
160000,1.4154197,99.0,-0.94539064,0.1025,0.1025,1.0
