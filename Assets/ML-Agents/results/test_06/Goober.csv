Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,2.7422442,99.0,-1.1003004,-11.38888888888889,-11.38888888888889,1.0
20000,2.7401645,99.0,-0.9717977,-13.255,-13.255,1.0
30000,2.7373888,99.0,-1.2015293,-10.365,-10.365,1.0
40000,2.7085302,99.0,-1.9337765,-11.88,-11.88,1.0
50000,2.7137036,99.0,-1.8732136,-10.765,-10.765,1.0
60000,2.6836307,99.0,-2.4271722,-14.375,-14.375,1.0
70000,2.6813245,99.0,-2.5465019,-10.97,-10.97,1.0
80000,2.6718316,99.0,-2.8046148,-13.09,-13.09,1.0
90000,2.685766,99.0,-2.825401,-9.58,-9.58,1.0
100000,2.639376,99.0,-2.7780719,-10.1175,-10.1175,1.0
110000,2.6344488,99.0,-3.2567773,-10.66,-10.66,1.0
120000,2.5625849,99.0,-3.971969,-10.51,-10.51,1.0
130000,2.5664241,99.0,-4.03095,-12.29,-12.29,1.0
140000,2.5573452,99.0,-4.196037,-11.4525,-11.4525,1.0
150000,2.578413,99.0,-4.061351,-10.225,-10.225,1.0
160000,2.5554729,99.0,-4.348381,-9.805,-9.805,1.0
170000,2.557618,99.0,-4.928487,-10.355,-10.355,1.0
