Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,2.7675843,99.0,-2.374902,-13.535353535353535,-13.535353535353535,1.0
20000,2.7667139,99.0,-2.6246371,-11.08,-11.08,1.0
30000,2.76685,99.0,-2.8400478,-13.96,-13.96,1.0
40000,2.7629476,99.0,-3.2032547,-10.3,-10.3,1.0
50000,2.7619777,99.0,-3.4825525,-9.625,-9.625,1.0
60000,2.7486794,99.0,-4.128421,-9.99,-9.99,1.0
70000,2.745041,99.0,-4.386987,-12.815,-12.815,1.0
80000,2.724812,99.0,-4.8430347,-11.555,-11.555,1.0
90000,2.7293687,99.0,-4.794798,-12.465,-12.465,1.0
100000,2.7015767,99.0,-4.931286,-11.1275,-11.1275,1.0
110000,2.7143986,99.0,-5.169424,-11.47,-11.47,1.0
120000,2.7065423,99.0,-5.305084,-10.555,-10.555,1.0
130000,2.7044742,99.0,-5.397973,-12.755,-12.755,1.0
140000,2.6788726,99.0,-6.9966,-10.365,-10.365,1.0
