Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,2.765352,99.0,-4.0930634,-7.2272727272727275,-7.2272727272727275,1.0
20000,2.761222,99.0,-4.008831,-10.105,-10.105,1.0
30000,2.754065,99.0,-4.1011906,-9.495,-9.495,1.0
40000,2.754429,99.0,-3.897813,-10.855,-10.855,1.0
50000,2.742469,99.0,-4.04771,-8.765,-8.765,1.0
60000,2.758445,99.0,-4.182353,-10.1275,-10.1275,1.0
70000,2.7560732,99.0,-4.0870376,-8.42,-8.42,1.0
80000,2.7602422,99.0,-4.184882,-11.575,-11.575,1.0
90000,2.7566736,99.0,-4.22998,-13.36,-13.36,1.0
100000,2.7541819,99.0,-4.360748,-10.955,-10.955,1.0
110000,2.7593334,99.0,-4.397176,-12.545,-12.545,1.0
120000,2.7480733,99.0,-4.413592,-10.355,-10.355,1.0
130000,2.7474127,99.0,-4.5439568,-8.615,-8.615,1.0
140000,2.7471602,99.0,-4.68886,-8.215,-8.215,1.0
150000,2.7250261,99.0,-4.966587,-9.2,-9.2,1.0
160000,2.720063,99.0,-5.1749005,-9.77,-9.77,1.0
170000,2.7035959,99.0,-5.4821367,-9.33,-9.33,1.0
