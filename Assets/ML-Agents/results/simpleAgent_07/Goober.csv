Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,2.7724917,99.0,0.085731514,-19.242424242424242,-19.242424242424242,1.0
20000,2.7724948,99.0,0.07775827,-18.285,-18.285,1.0
30000,2.7650297,99.0,-0.18854603,-16.75,-16.75,1.0
40000,2.7641735,99.0,-0.20520283,-15.915,-15.915,1.0
50000,2.7513607,99.0,-0.52008104,-14.14,-14.14,1.0
60000,2.751799,99.0,-0.6106387,-18.66,-18.66,1.0
70000,2.7476437,99.0,-0.8316154,-15.47,-15.47,1.0
80000,2.7438302,99.0,-0.9301897,-15.04,-15.04,1.0
90000,2.7298172,99.0,-1.1129427,-15.2,-15.2,1.0
100000,2.731298,99.0,-1.1776341,-14.03,-14.03,1.0
110000,2.6990976,99.0,-1.3629705,-14.385,-14.385,1.0
120000,2.6944811,99.0,-1.4276413,-12.875,-12.875,1.0
