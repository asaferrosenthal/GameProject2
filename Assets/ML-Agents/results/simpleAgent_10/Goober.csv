Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,99.0,-0.5801217,-0.7626262626262627,-0.7626262626262627,1.0
20000,1.4189383,99.0,-0.57496613,-1.85,-1.85,1.0
30000,1.4175287,99.0,-0.6009874,-0.99,-0.99,1.0
40000,1.4175287,99.0,-0.6176414,-1.795,-1.795,1.0
50000,1.4184221,99.0,-0.64487296,-3.375,-3.375,1.0
60000,1.4184219,99.0,-0.6115903,-3.325,-3.325,1.0
70000,1.418422,99.0,-0.6974844,-1.75,-1.75,1.0
80000,1.4180052,99.0,-0.77626455,-1.62,-1.62,1.0
90000,1.4172447,99.0,-0.78257203,-2.405,-2.405,1.0
100000,1.4172446,99.0,-0.83368737,-0.315,-0.315,1.0
110000,1.4172446,99.0,-0.7903994,-1.585,-1.585,1.0
120000,1.4167575,99.0,-0.7473397,-1.5,-1.5,1.0
130000,1.4167575,99.0,-1.1000781,-3.985,-3.985,1.0
